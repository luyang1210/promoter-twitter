#'MRF cross validation to optimise regularization parameters
#'
#'This function runs \code{\link{MRFcov}} models across a specified
#'range of l1−regularization values, using x-fold cross validation
#'to assess model predictive performance at each l1 value.
#'
#'@importFrom magrittr %>%
#'@importFrom parallel makePSOCKcluster setDefaultCluster clusterExport stopCluster clusterEvalQ parLapply
#'
#'@param data Dataframe. The input data where the \code{n_nodes}
#'left-most variables are binary occurrences to be represented by nodes in the graph.
#'Note that \code{NA}'s are allowed for covariates. If present, these missing values
#'will be imputed from the distribution \code{rnorm(mean = 0, sd = 1)}, which assumes that
#'all covariates are scaled and centred (i.e. by using the function
#'\code{\link[base]{scale}} or similar)
#'@param min_lambda1 Positive numeric. The lowest l1−regularization value to be tested
#'@param max_lambda1 Positive numeric. The highest l1−regularization value to be tested
#'@param by_lambda1 Positive numeric. The increment of the l1 test_data sequence.
#'The test sequence is generated by calling \code{lamda1_seq = seq(min_lambda1, max_lambda1, by_lambda1)}
#'@param lambda2 Numeric (>= 0). Value for l2−regularization, where larger values lead
#'to stronger shrinking of coefficient magnitudes. Default is 0, but larger values
#'may be necessary for large or particularly sparse datasets
#'@param separate_min Logical. If \strong{TRUE}, interaction coefficients will use the minimum absolute value of
#'the corresponding parameter estimates, which are taken from separate logistic regressions,
#' in the symmetric postprocessed coefficient matrix. Else use the maximum. Default is \strong{FALSE}
#'@param n_nodes Positive integer. The index of the last column in data
#'which is represented by a node in the final graph. Columns with index
#'greater than n_nodes are taken as covariates. Default is the number of
#'columns in data, corresponding to no additional covariates
#'@param n_cores Positive integer. The number of cores to spread the job across using
#'\code{\link[parallel]{makePSOCKcluster}}. Default is 1 (no parallelisation)
#'@param n_folds Positive integer. The number of folds for cross-validation. Default is 10
#'@param n_fold_runs Positive integer. The number of total training runs to perform at each
#'l1 regularization parameter. Defaults to \code{n_folds}
#'@param n_covariates Positive integer. The number of covariates in \code{data},
#'before cross-multiplication
#'@param sample_seed Numeric. This seed will be used as the basis
#'for dividing data into folds. Default is a random seed
#'between 1 and 100000
#'@return A \code{list} of 11 objects:
#'\itemize{
#'    \item \code{mean_pos_pred}: Numeric value of average positive predictive value
#'    \item \code{mean_neg_pred}: Numeric value of average negative predictive value
#'    \item \code{mean_tot_pred}: Numeric value of average total rate of correct predictions
#'    \item \code{mean_sensitivity}: Numeric value of average sensitivity
#'    \item \code{mean_specificity}: Numeric value of average specificity
#'    \item \code{pos_pred}: Vector of positive predictive values
#'    \item \code{neg_pred}: Vector of negative predictive values
#'    \item \code{tot_pred}: Vector of rate of correct predictions
#'    \item \code{sensitivity}: Vector of sensitivity values
#'    \item \code{specificity}: Vector of specificity values
#'    \item \code{lambda1}: Vector of lambda l1 regularization values
#'    }
#'
#'
#'@seealso \code{\link{MRFcov}},\code{\link{predict_MRF}},
#'\code{\link{cv_MRF_diag}}, \code{\link[penalized]{penalized}}
#'
#'@export
#'
cv_MRF <- function(data, min_lambda1, max_lambda1, by_lambda1,
                  lambda2, separate_min,
                  n_nodes, n_cores, sample_seed, n_folds,
                  n_fold_runs, n_covariates){

  #### Specify default parameter values and initiate warnings ####
  if(missing(separate_min)) {
    separate_min <- FALSE
  }

  if(missing(n_folds)) {
    n_folds <- 10
  } else {
    if(sign(n_folds) == 1){
      #Make sure n_folds is a positive integer
      n_folds = ceiling(n_folds)
    } else {
      stop('Please provide a positive integer for n_folds')
    }
  }

  if(missing(n_fold_runs)) {
    n_fold_runs <- n_folds
  } else {
    if(sign(n_fold_runs) == 1){
      #Make sure n_fold_runs is a positive integer
      n_fold_runs = ceiling(n_fold_runs)
    } else {
      stop('Please provide a positive integer for n_fold_runs')
    }
  }

  if(missing(lambda2)) {
    lambda2 <- 0
  } else {
    if(lambda2 < 0){
      stop('Please provide a non-negative numeric value for lambda2')
    }
  }

  if(missing(n_cores)) {
    n_cores <- 1
  } else {
    if(sign(n_cores) != 1){
      stop('Please provide a positive integer for n_cores')
    } else{
      if(sfsmisc::is.whole(n_cores) == FALSE){
        stop('Please provide a positive integer for n_cores')
      }
    }
  }

  if(missing(n_covariates)){
    n_covariates <- ncol(data) - n_nodes
  } else {
    if(sign(n_covariates) != 1){
      stop('Please provide a positive integer for n_covariates')
    } else {
      if(sfsmisc::is.whole(n_covariates) == FALSE){
        stop('Please provide a positive integer for n_covariates')
      }
    }
  }

  if(length(n_covariates) == 0){
    n_covariates <- 0
  }

  if(missing(n_nodes)) {
    warning('n_nodes not specified. using ncol(data) as default, assuming no covariates',
            call. = FALSE)
    n_nodes <- ncol(data)
    n_covariates <- 0
  } else {
    if(sign(n_nodes) != 1){
      stop('Please provide a positive integer for n_nodes')
    } else {
      if(sfsmisc::is.whole(n_nodes) == FALSE){
        stop('Please provide a positive integer for n_nodes')
      }
    }
  }

  if(n_covariates > 0){
    if(any(is.na(data[, (n_nodes + 1):ncol(data)]))){
      warning('NAs detected in covariate columns. These will be imputed from rnorm(mean=0,sd=1)',
              call. = FALSE)
      nas_present <- TRUE
      } else {
        nas_present <- FALSE
  }
  } else {
    nas_present <- FALSE
  }

  if(missing(sample_seed)) {
  sample_seed <- ceiling(runif(1, 0, 100000))
  }
  set.seed(sample_seed)

#### Function to impute NAs from normal distribution (mean=0; sd=1) ####
impute_nas <- function(empty){
  data[is.na(data)] <- sample(rnorm(sum(is.na(data)),
                                    mean = 0, sd = 1),
                              replace = FALSE)
  data <- data
}

#### Run cross-validated MRF models across the sequence of lambda1 values ####
lamda1_seq <- seq(min_lambda1, max_lambda1, by_lambda1)

#Check if non-dependent libraries can be loaded on parallel clusters
if(n_cores > 1){
  #Initiate the n_cores parallel clusters
  cl <- makePSOCKcluster(n_cores)
  setDefaultCluster(cl)

  #### Check for errors when directly loading a necessary library on each cluster ####
  test_load1 <- try(clusterEvalQ(cl, library(purrr)), silent = TRUE)

  #If errors produced, iterate through other options for library loading
  if(class(test_load1) == "try-error") {

    #Try finding unique library paths using system.file()
    pkgLibs <- unique(c(sub("/purrr$", "", system.file(package = "purrr"))))
    clusterExport(NULL, c('pkgLibs'), envir = environment())
    clusterEvalQ(cl, .libPaths(pkgLibs))

    #Check again for errors loading libraries
    test_load2 <- try(clusterEvalQ(cl, library(purrr)), silent = TRUE)

    if(class(test_load2) == "try-error"){

      #Try loading the user's .libPath() directly
      clusterEvalQ(cl,.libPaths(as.character(.libPaths())))
      test.3 <- try(clusterEvalQ(cl, library(penalized)), silent = TRUE)

      if(class(test_load3) == "try-error"){

        #Give up and use lapply instead!
        parallel_compliant <- FALSE
        stopCluster(cl)

      } else {
        parallel_compliant <- TRUE
      }

    } else {
      parallel_compliant <- TRUE
    }

  } else {
    parallel_compliant <- TRUE
  }
} else {
  parallel_compliant <- FALSE
}

#### If parallel loading passes, proceed with parLapply calls ####
if(parallel_compliant){

#Prep the data for MRF models
if(nas_present){

  #Create list of 100 datasets that have been treated for nas
  imputed_list <- vector('list', 100)
  imputed_datas <- lapply(imputed_list, impute_nas)
  rm(imputed_list)

  clusterExport(NULL, c('prep_MRF_covariates'))
  clusterExport(NULL, c('n_nodes','imputed_datas'),
                envir=environment())

  prepped_datas <- parLapply(NULL, imputed_datas, prep_MRF_covariates,
                       n_nodes = n_nodes)

} else {
  prepped_datas <- prep_MRF_covariates(data = data,
                          n_nodes = n_nodes)
}

#Export necessary data and variables to each cluster
clusterExport(NULL, c('lamda1_seq', 'n_folds', 'lambda2',
                      'separate_min', 'n_nodes',
                      'data','nas_present', 'n_covariates',
                      'prepped_datas', 'n_fold_runs'),
                envir = environment())

#Export necessary functions
clusterExport(NULL, c('MRFcov','predict_MRF'))

#Export necessary libraries
clusterEvalQ(cl, library('purrr'))
clusterEvalQ(cl, library('dplyr'))
clusterEvalQ(cl, library('penalized'))
clusterEvalQ(cl, library('data.table'))
clusterEvalQ(cl, library('caret'))

cross_validated_mrfs <- parLapply(NULL, lamda1_seq, function(l) {

  #Create folds from the prepped data for cross-validation
  if(nas_present){
    folds <- caret::createFolds(rownames(prepped_datas[[1]]), n_folds)
  } else {
    folds <- caret::createFolds(rownames(prepped_datas), n_folds)
}
  pos_pred <- rep(NA, n_folds)
  neg_pred <- rep(NA, n_folds)
  sensitivity <- rep(NA, n_folds)
  specificity <- rep(NA, n_folds)
  tot_pred <- rep(NA, n_folds)

  for(k in seq_len(n_fold_runs)){

    if(nas_present){
    #Randomly sample an imputed dataset
    draw <- sample(seq_along(prepped_datas), 1)
    mrf_datas <- prepped_datas[[draw]]
    } else {
      mrf_datas <- prepped_datas
    }

    #Split the prepped data into test and training folds
    training_data <- mrf_datas[-folds[[k]], ]
    test_data <- mrf_datas[folds[[k]], ]

    #Run the model using the training dataset
    trained_mrf <- MRFcov(data = training_data, lambda1 = l,
                     lambda2 = lambda2,
                     separate_min = separate_min,
                     n_nodes = n_nodes,
                     n_cores = 1, prep_covariates = FALSE,
                     n_covariates = n_covariates)

    #Use output from the trained model to predict the test_data observations
    test_preds <- predict_MRF(data = test_data, MRF_mod = trained_mrf,
                           n_nodes = n_nodes)

    rm(trained_mrf, training_data, mrf_datas) #remove un-needed objects to free up memory

    #Calculate positive and negative predictive values
    true_pos <- false_pos <- true_neg <- false_neg <- matrix(NA, ncol = ncol(test_preds[[1]]),
                                                    nrow = nrow(test_preds[[1]]))
    for(i in seq_len(nrow(true_pos))){
      for(j in seq_len(ncol(true_pos))){
        true_pos[i, j] <- isTRUE(all.equal(as.numeric(test_preds[[1]][i, j]),
                                         as.numeric(test_data[i, j]))) &
          isTRUE(all.equal(as.numeric(test_preds[[1]][i, j]), 1))

        false_pos[i, j] <- !isTRUE(all.equal(as.numeric(test_preds[[1]][i, j]),
                                           as.numeric(test_data[i, j]))) &
          isTRUE(all.equal(as.numeric(test_preds[[1]][i, j]), 1))

        true_neg[i, j] <- isTRUE(all.equal(as.numeric(test_preds[[1]][i, j]),
                                          as.numeric(test_data[i, j]))) &
          isTRUE(all.equal(as.numeric(test_preds[[1]][i, j]), 0))

        false_neg[i, j] <- !isTRUE(all.equal(as.numeric(test_preds[[1]][i, j]),
                                           as.numeric(test_data[i, j]))) &
          isTRUE(all.equal(as.numeric(test_preds[[1]][i, j]), 0))
      }
    }

    #Calculate diagnostic predictive values
  pos_pred[k] <- sum(true_pos, na.rm = TRUE) /
                (sum(true_pos, na.rm = TRUE) + sum(false_pos, na.rm = TRUE))
  neg_pred[k] <- sum(true_neg, na.rm = TRUE) /
                (sum(true_neg, na.rm = TRUE) + sum(false_neg, na.rm = TRUE))
  sensitivity[k] <- sum(true_pos, na.rm = TRUE) /
                (sum(true_pos, na.rm = TRUE) + sum(false_neg, na.rm = TRUE))
  specificity[k] <- sum(true_neg, na.rm = TRUE) /
                (sum(true_neg, na.rm = TRUE) + sum(false_pos, na.rm = TRUE))
  tot_pred[k] <- (sum(true_pos, na.rm = TRUE) + sum(true_neg, na.rm = TRUE)) /
                (length(true_pos))
  }

list(mean_pos_pred = mean(pos_pred, na.rm = TRUE),
     mean_neg_pred = mean(neg_pred, na.rm = TRUE),
     mean_tot_pred = mean(tot_pred, na.rm = TRUE),
     mean_sensitivity = mean(sensitivity, na.rm = TRUE),
     mean_specificity = mean(specificity, na.rm = TRUE),
     pos_pred = pos_pred, neg_pred = neg_pred,
     tot_pred = tot_pred, sensitivity = sensitivity,
     specificity = specificity, lambda1 = l)
})
stopCluster(cl)

} else {
  #### Use lapply calls if n_cores = 1 and/or if parallel library loading fails ####
  #Prep the data for MRF models
  if(nas_present){
    prepped_datas <-lapply(imputed_datas, prep_MRF_covariates,
                         n_nodes = n_nodes)
  } else {
    prepped_datas <- prep_MRF_covariates(data = data,
                            n_nodes = n_nodes)
  }

  cross_validated_mrfs <- lapply(lamda1_seq, function(l) {

    #Create folds for cross-validation
    if(nas_present){
      folds <- caret::createFolds(rownames(prepped_datas[[1]]), n_folds)
    } else {
      folds <- caret::createFolds(rownames(prepped_datas), n_folds)
    }
    pos_pred <- rep(NA, n_folds)
    neg_pred <- rep(NA, n_folds)
    sensitivity <- rep(NA, n_folds)
    specificity <- rep(NA, n_folds)
    tot_pred <- rep(NA, n_folds)

    for(k in seq_len(n_fold_runs)){

      if(nas_present){
        #randomly sample an imputed dataset
        draw <- sample(seq_along(prepped_datas), 1)
        data <- prepped_datas[[draw]]
      }

      #Split data into test_data and training folds
      training_data <- prepped_datas[-folds[[k]],]
      test_data <- prepped_datas[folds[[k]],]

      #Run the models
      trained_mrf <- MRFcov(data = training_data, lambda1 = l,
                       lambda2 = lambda2,
                       separate_min = separate_min,
                       n_nodes = n_nodes,
                       n_cores = 1, prep_covariates = FALSE,
                       n_covariates = n_covariates)

      test_preds <- predict_MRF(data = test_data, MRF_mod = trained_mrf,
                            n_nodes = n_nodes)

      rm(trained_mrf, training_data) #remove un-needed objects to free up memory

      #Calculate positive and negative predictive values
      true_pos <- false_pos <- true_neg <- false_neg <- matrix(NA, ncol = ncol(test_preds[[1]]),
                                                     nrow = nrow(test_preds[[1]]))
      for(i in seq_len(nrow(true_pos))){
        for(j in seq_len(ncol(true_pos))){
          true_pos[i, j] <- isTRUE(all.equal(as.numeric(test_preds[[1]][i, j]),
                                            as.numeric(test_data[i, j]))) &
            isTRUE(all.equal(as.numeric(test_preds[[1]][i ,j]), 1))

          false_pos[i, j] <- !isTRUE(all.equal(as.numeric(test_preds[[1]][i, j]),
                                             as.numeric(test_data[i, j]))) &
            isTRUE(all.equal(as.numeric(test_preds[[1]][i, j]), 1))

          true_neg[i, j] <- isTRUE(all.equal(as.numeric(test_preds[[1]][i, j]),
                                            as.numeric(test_data[i, j]))) &
            isTRUE(all.equal(as.numeric(test_preds[[1]][i ,j]), 0))

          false_neg[i, j] <- !isTRUE(all.equal(as.numeric(test_preds[[1]][i, j]),
                                             as.numeric(test_data[i, j]))) &
            isTRUE(all.equal(as.numeric(test_preds[[1]][i, j]), 0))
        }
      }

      pos_pred[k] <- sum(true_pos, na.rm = TRUE) /
        (sum(true_pos, na.rm = TRUE) + sum(false_pos, na.rm = TRUE))
      neg_pred[k] <- sum(true_neg, na.rm = TRUE) /
        (sum(true_neg, na.rm = TRUE) + sum(false_neg, na.rm = TRUE))
      sensitivity[k] <- sum(true_pos, na.rm = TRUE) /
        (sum(true_pos, na.rm = TRUE) + sum(false_neg, na.rm = TRUE))
      specificity[k] <- sum(true_neg, na.rm = TRUE) /
        (sum(true_neg, na.rm = TRUE) + sum(false_pos, na.rm = TRUE))
      tot_pred[k] <- (sum(true_pos, na.rm = TRUE) + sum(true_neg, na.rm = TRUE)) /
        (length(true_pos))
    }

    list(mean_pos_pred = mean(pos_pred, na.rm = TRUE),
         mean_neg_pred = mean(neg_pred, na.rm = TRUE),
         mean_tot_pred = mean(tot_pred, na.rm = TRUE),
         mean_sensitivity = mean(sensitivity, na.rm = TRUE),
         mean_specificity = mean(specificity, na.rm = TRUE),
         pos_pred = pos_pred, neg_pred = neg_pred,
         tot_pred = tot_pred, sensitivity = sensitivity,
         specificity = specificity, lambda1 = l)
  })

}
return(cross_validated_mrfs)

}
