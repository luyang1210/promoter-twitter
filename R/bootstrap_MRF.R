#'Bootstrap observations to estimate MRF parameter coefficients
#'
#'This function runs \code{\link{MRFcov}} models multiple times using either a user-specified
#'range of l1 regularization values or cross-validation. To capture uncertainty
#'in paramter esimates, the dataset is bootstrapped a user-specified number of times in each iteration.
#'
#'@importFrom magrittr %>%
#'@importFrom parallel makePSOCKcluster setDefaultCluster clusterExport stopCluster clusterEvalQ parLapply
#'
#'@param data Dataframe. The input data where the \code{n_nodes}
#'left-most variables are binary occurrences to be represented by nodes in the graph.
#'Note that \code{NA}'s are allowed for covariates. If present, these missing values
#'will be imputed from the distribution \code{rnorm(mean = 0, sd = 1)}, which assumes that
#'all covariates are scaled and centred (i.e. by using the function
#'\code{\link[base]{scale}} or similar)
#'@param n_bootstraps Positive integer. Represents the total number of bootstrap samples
#'to test in each iteration. Default is 100.
#'@param min_lambda1 Positive numeric. The lowest l1−regularization value to be tested.
#'If \code{cv = TRUE}, this value is ignored and penalization parameters are optimized automatially
#'@param max_lambda1 Positive numeric. The highest l1−regularization to be tested.
#'If \code{cv = TRUE}, this value is ignored and penalization parameters are optimized automatially
#'@param by_lambda1 Positive numeric. The increment of the l1 test sequence. The test sequence is generated by calling
#'\code{lambda1_seq = seq(min_lambda1, max_lambda1, by_lambda1)}.
#'If \code{cv = TRUE}, this value is ignored and penalization parameters are optimized automatially.
#'@param lambda2 Numeric (>= 0). Value for l2−regularization, where larger values lead
#'to stronger shrinking of coefficient magnitudes. Default is 0, but larger values
#'may be necessary for large or particularly sparse datasets
#'@param separate_min Logical. If \strong{TRUE}, interaction coefficients will use the minimum absolute value of
#'the corresponding parameter estimates, which are taken from separate logistic regressions,
#' in the symmetric postprocessed coefficient matrix. Else use the maximum. Default is \strong{FALSE}
#'@param sample_seed Numeric. Used as the seed value for generating bootstrap replicates, allowing
#'users to generate replicated datasets on different systems. Default is a random seed
#'@param n_nodes Positive integer. The index of the last column in \code{data}
#'which is represented by a node in the final graph. Columns with index
#'greater than n_nodes are taken as covariates. Default is the number of
#'columns in \code{data}, corresponding to no additional covariates
#'@param n_cores Integer. The number of cores to spread the job across using
#'\code{\link[parallel]{makePSOCKcluster}}. Default is 1 (no parallelisation)
#'@param n_covariates Positive integer. The number of covariates in \code{data},
#'before cross-multiplication. Default is \code{ncol(data) - n_nodes}
#'@param family The response type. Responses can be quantitative continuous (\code{family = "gaussian"}),
#'non-negative counts (\code{family = "poisson"}) or binomial 1s and 0s (\code{family = "binomial"})
#'@param cv Logical. If \code{TRUE}, node-specific regressions are optimized using the 10-fold
#'cross-validation procedure in \code{\link[glmnet]{cv.glmnet}} to find the \code{lambda1} value
#'that minimises mean cross-validated error. If \code{FALSE}, each regression is run
#'at a single \code{lambda1} value (the same \code{lambda1} value is used for each separate
#'regression). Default is \code{TRUE}, meaning that arguments to \code{min_lambda1}, \code{max_lambda1}
#'and \code{by_lambda1} are ignored
#'@param n_its Positive integer. The number of iterations to perform \code{n_bootstrap} replicates
#'across. If \code{cv = FALSE}, this value is ignored and \code{n_its} is taken from the length of
#'\code{lambda1_seq = seq(min_lambda1, max_lambda1, by_lambda1)}. Default when \code{cv = FALSE}
#'is \code{100}
#'@return A \code{list} containing five objects:
#'\itemize{
#'   \item \code{lambda_results}: \code{list} of length \code{lambda1_seq} containing:
#'   \itemize{
#'   \item \code{key_covariates}: dataframes of important covariates (i.e. those retained in
#'   at least 90 percent of bootstrap replicates) at each l1 value
#'   \item \code{raw_coefs}: the raw estimated coefficients at each l1 value
#'   \item \code{indirect_coefs}: estimated higher order interaction coefficients at each l1 value
#'   }
#'   \item \code{direct_coef_means}: \code{dataframe} containing mean coefficient values taken from all
#'   bootstrapped models across the range of l1 values
#'   \item \code{direct_coef_upper90} and \code{direct_coef_lower90}: \code{dataframe}s
#'   containing coefficient 95 percent and 5 percent quantiles taken from all
#'   bootstrapped models across the range of l1 values
#'   \item \code{indirect_coef_mean}: \code{list} of matrices containing mean higher order coefficient values
#'   taken from all bootstrapped models across the range of l1 values
#'   \item \code{mean_key_coefs}: \code{list} of matrices of length \code{n_nodes}
#'   containing mean covariate coefficient values and their relative importances
#'   (using the formula \code{x^2 / sum (x^2)}
#'   taken from all bootstrapped models across iterations. Only coefficients
#'   with mean relative importances \code{>0.01} are returned. Note, relative importance are only
#'   useful if all covariates are on a similar scale.
#' }
#'
#'
#'@seealso \code{\link{MRFcov}},
#'\code{\link[penalized]{penalized}}
#'
#'@details \code{MRFcov} models are run across the specified sequence of \code{lambda1} values.
#'For each model, the \code{data} is bootstrapped by shuffling row observations, using
#'\code{dplyr::sample_n(data, nrow(data), TRUE)}, to account for uncertainty.
#'Parameter estimates from the set of bootstrapped models are summarised
#'to present confidence intervals.
#'
#'@examples
#'\dontrun{
#'data("Bird.parasites")
#'bootedCRF <- bootstrap_MRF(data = Bird.parasites,
#'                           n_nodes = 4, min_lambda1 = 0.5,
#'                           max_lambda1 = 1.25,
#'                           by_lambda1 = 0.25,
#'                           cv = FALSE, family = 'binomial')}
#'@export
#'
bootstrap_MRF <- function(data, n_bootstraps, sample_seed, min_lambda1,
                           max_lambda1, by_lambda1, lambda2, separate_min,
                           n_nodes, n_cores, n_covariates, cv, family, n_its){

  #### Specify default parameter values and initiate warnings ####
  if(!(family %in% c('gaussian', 'poisson', 'binomial')))
    stop('Please select one of the three family options: "gaussian", "poisson", "binomial"')

  if(missing(separate_min)) {
    separate_min <- FALSE
  }

  if(missing(n_bootstraps)) {
    n_bootstraps <- 100
  } else {
    if(sign(n_bootstraps) == 1){
    #Make sure n_bootstraps is a positive integer
    n_bootstraps = ceiling(n_bootstraps)
    } else {
      stop('Please provide a positive integer for n_bootstraps')
    }
  }

  if(missing(lambda2)) {
    lambda2 <- 0
  } else {
    if(sign(lambda2) != 1){
      stop('Please provide a non-negative numeric value for lambda2')
    }
  }

  if(missing(cv)){
    warning('cv not provided. Using cross-validated optimisation by default, ignoring min_lambda1, max_lambda1 and by_lambda1')
    cv <- TRUE
  }

  if(missing(n_its)) {
    n_its <- 100
  }

  #If cv is FALSE, check that lambda1 arguments are appropriate
  if(!cv){
  if(missing(min_lambda1)) {
    stop('Please provide a non-negative numeric value for min_lambda1')
  } else {
    if(min_lambda1 < 0){
      stop('Please provide a non-negative numeric value for min_lambda1')
    }
  }

  if(missing(max_lambda1)) {
    stop('Please provide a non-negative numeric value for max_lambda1')
  } else {
    if(max_lambda1 < 0){
      stop('Please provide a non-negative numeric value for max_lambda1')
    }
  }

  if(missing(by_lambda1)) {
    stop('Please provide a non-negative numeric value for by_lambda1')
  } else {
    if(by_lambda1 < 0){
      stop('Please provide a non-negative numeric value for by_lambda1')
    }
  }

  if(by_lambda1 > max_lambda1){
    stop('Please provide a by_lambda1 that can be used as an increment between min_lambda1 & max_lambda1')
  }
  }

  if(missing(n_nodes)) {
    warning('n_nodes not specified. using ncol(data) as default, assuming no covariates',
            call. = FALSE)
    n_nodes <- ncol(data)
    n_covariates = 0
  } else {
    if(sign(n_nodes) != 1){
      stop('Please provide a positive integer for n_nodes')
    } else {
      if(sfsmisc::is.whole(n_nodes) == FALSE){
        stop('Please provide a positive integer for n_nodes')
      }
    }
  }

  if(missing(n_covariates)){
    n_covariates <- ncol(data) - n_nodes
  } else {
    if(sign(n_covariates) != 1){
      stop('Please provide a positive integer for n_covariates')
    } else {
      if(sfsmisc::is.whole(n_covariates) == FALSE){
        stop('Please provide a positive integer for n_covariates')
      }
    }
  }

  if(any(is.na(data[,(n_nodes + 1):ncol(data)]))){
    warning('NAs detected in covariate columns. These will be imputed from rnorm(mean=0,sd=1)',
            call. = FALSE)
    nas_present = TRUE
  } else {
    nas_present = FALSE
    }

  if(missing(n_cores)) {
    n_cores <- 1
  } else {
    if(sign(n_cores) != 1){
      stop('Please provide a positive integer for n_cores')
    } else{
      if(sfsmisc::is.whole(n_cores) == FALSE){
        stop('Please provide a positive integer for n_cores')
      }
    }
  }

  if(is.matrix(data)){
    data <- as.data.frame(data)
  }

  if(missing(sample_seed)){
    set.seed(ceiling(runif(1, 0, 100000)))
  } else {
    set.seed(sample_seed)
  }

  #### Function to randomly sample rows for each bootstrap replicate ####
  shuffle_rows <- function(empty){
    dplyr::sample_n(data, nrow(data), TRUE)
  }

  #### Function to impute NAs from normal distribution (mean = 0; sd = 1) ####
  impute_nas <- function(empty){
    data[is.na(data)] <- sample(rnorm(sum(is.na(data)),
                                      mean = 0, sd = 1),
                                replace = FALSE)
    data <- data
  }

  #### Create list of bootstrapped datasets; impute NAs if needed ####
  booted_list <- vector('list', n_bootstraps)
  booted_datas <- lapply(booted_list, shuffle_rows)
  rm(booted_list)

  if(nas_present){
  booted_datas <- lapply(booted_datas,impute_nas)
  }

  #### Run MRFcov across the sequence of lambda1 values ####
  if(cv){
    #If using cross-validation, lambda1_seq doesn't matter (just needs to be a sequence for
    #running models repeatedly. Uses n_its to define the length)
    lambda1_seq <- seq(1, 10, n_its)

  } else {
    lambda1_seq <- seq(min_lambda1, max_lambda1, by_lambda1)
  }

  #### If n_cores > 1, check parallel library loading ####
  if(n_cores > 1){
    #Initiate the n_cores parallel clusters
    cl <- makePSOCKcluster(n_cores)
    setDefaultCluster(cl)

    #### Check for errors when directly loading a necessary library on each cluster ####
    test_load1 <- try(clusterEvalQ(cl, library(purrr)), silent = TRUE)

    #If errors produced, iterate through other options for library loading
    if(class(test_load1) == "try-error") {

      #Try finding unique library paths using system.file()
      pkgLibs <- unique(c(sub("/purrr$", "", system.file(package = "purrr"))))
      clusterExport(NULL, c('pkgLibs'), envir = environment())
      clusterEvalQ(cl, .libPaths(pkgLibs))

      #Check again for errors loading libraries
      test_load2 <- try(clusterEvalQ(cl, library(purrr)), silent = TRUE)

      if(class(test_load2) == "try-error"){

        #Try loading the user's .libPath() directly
        clusterEvalQ(cl,.libPaths(as.character(.libPaths())))
        test_load3 <- try(clusterEvalQ(cl, library(penalized)), silent = TRUE)

        if(class(test_load3) == "try-error"){

          #Give up and use lapply instead!
          parallel_compliant <- FALSE
          stopCluster(cl)

        } else {
          parallel_compliant <- TRUE
        }

      } else {
        parallel_compliant <- TRUE
      }

    } else {
      parallel_compliant <- TRUE
    }
  } else {
    #If n_cores = 1, set parallel_compliant to FALSE
    parallel_compliant <- FALSE
  }

 #### If parallel support confirmed and n_cores > 1, proceed with parLapply ####
  if(parallel_compliant){

    #Export necessary data and variables to each cluster
    clusterExport(NULL, c('lambda1_seq', 'booted_datas', 'lambda2',
                          'separate_min', 'n_nodes',
                          'n_covariates', 'cv', 'family'), envir = environment())

    #Export necessary functions to each cluster
    clusterExport(NULL, c('MRFcov', 'countzero', 'prep_MRF_covariates'))

    #Export necessary libraries
    clusterEvalQ(cl, library(purrr))
    clusterEvalQ(cl, library(dplyr))
    clusterEvalQ(cl, library(penalized))
    clusterEvalQ(cl, library(data.table))

    #Prep the list of booted datasets for MRF models
    prepped_datas <-parLapply(NULL, booted_datas, prep_MRF_covariates,
                         n_nodes = n_nodes)

    clusterExport(NULL, c('prepped_datas'),
                  envir = environment())

    lambda_results <- parLapply(NULL, lambda1_seq, function(l) {
      booted_mrfs <- lapply(seq_along(booted_datas), function(x) {
        mod <- MRFcov(data = prepped_datas[[x]], lambda1 = l,
                      lambda2 = lambda2,
                      separate_min = separate_min,
                      n_nodes = n_nodes,
                      n_cores = 1,
                      prep_covariates = FALSE,
                      n_covariates = n_covariates,
                      cv = cv, family = family)

        list(direct_coefs = mod$direct_coefs,
             indirect_coefs = mod$indirect_coefs)
  })

    #Gather direct effect estimates from all bootstrap samples
    direct_coef_list <- booted_mrfs %>%
      purrr::map('direct_coefs')

    #Calculate mean coefficient estimates across bootstrap samples
    direct_coef_means <- apply(array(unlist(direct_coef_list),
                              c(nrow(booted_mrfs[[1]]$direct_coefs),
                                ncol(booted_mrfs[[1]]$direct_coefs),
                                length(booted_mrfs))), c(1, 2), mean)

    rownames(direct_coef_means) <- rownames(booted_mrfs[[1]]$direct_coefs)
    colnames(direct_coef_means) <- colnames(booted_mrfs[[1]]$direct_coefs)

    #Calculate proportion of bootstrap models in which each cofficient is non-zero
    n_total_covariates <- ncol(booted_mrfs[[1]]$direct_coefs)

    prop_covs_retained <- matrix(0, n_nodes, n_total_covariates)
    for(i in seq_len(n_nodes)){
      for(j in seq_len(n_total_covariates)){
        prop_covs_retained[i, j] <- 1 - countzero(booted_mrfs, i, j)
      }
    }
    rownames(prop_covs_retained) <- rownames(booted_mrfs[[1]]$direct_coefs)
    colnames(prop_covs_retained) <- colnames(booted_mrfs[[1]]$direct_coefs)

    #Create list of covariates that are not zero for each node in data
    key_covariates <- lapply(seq_len(n_nodes), function(x){
      cov_prop_retained <- apply(data.frame(prop_covs_retained)[x,], 2,
                            function(j) ifelse(j < 0.89, NA, j))
      cov_mean_coef <- as.vector(direct_coef_means[x,])
      cov_summary <- na.omit(cbind(cov_prop_retained, cov_mean_coef))
      cleaned_prop_retained <- cov_prop_retained[!is.na(cov_prop_retained)]
      cov_df <- data.frame(Proportion_retained = cleaned_prop_retained,
                                Mean_coefficient = cov_summary[, 2])
      cov_df <- cov_df[order(-abs(cov_df[, 2])),]
      })
    names(key_covariates) <- colnames(prepped_datas[[1]])[1:n_nodes]

    #Calculate mean indirect interaction estimates from bootstrapped models
    indirect_coef_list <- booted_mrfs %>%
      purrr::map('indirect_coefs')

    indirect_coef_means <-lapply(seq_along(indirect_coef_list[[1]]), function(x){
      Reduce(`+`, sapply(indirect_coef_list, "[[", x)) / length(indirect_coef_list)
      })
    names(indirect_coef_means) <- names(indirect_coef_list[[1]])

    list(key_covariates = key_covariates,
         raw_coefs = direct_coef_list,
         indirect_coefs = indirect_coef_means)
  })
  stopCluster(cl)

    } else {

 #### If parallel loading fails, or if n_cores = 1, use lapply instead ####
      prepped_datas <-lapply(booted_datas, prep_MRF_covariates,
                           n_nodes = n_nodes)

      lambda_results <- lapply(lambda1_seq, function(l) {
        booted_mrfs <- lapply(seq_along(booted_datas), function(x) {
          mod <- MRFcov(data = prepped_datas[[x]], lambda1 = l,
                        lambda2 = lambda2,
                        separate_min = separate_min,
                        n_nodes = n_nodes,
                        n_cores = 1,
                        prep_covariates = FALSE,
                        n_covariates = n_covariates,
                        cv = cv, family = family)

          list(direct_coefs = mod$direct_coefs,
               indirect_coefs = mod$indirect_coefs)
        })

        direct_coef_list <- booted_mrfs %>%
          purrr::map('direct_coefs')

        direct_coef_means <- apply(array(unlist(direct_coef_list),
                                  c(nrow(booted_mrfs[[1]]$direct_coefs),
                                    ncol(booted_mrfs[[1]]$direct_coefs),
                                    length(booted_mrfs))), c(1,2), mean)
        rownames(direct_coef_means) <- rownames(booted_mrfs[[1]]$direct_coefs)
        colnames(direct_coef_means) <- colnames(booted_mrfs[[1]]$direct_coefs)

        #Calculate proportion of bootstrap samps in which each direct coefficient occurs
        n_total_covariates <- ncol(booted_mrfs[[1]]$direct_coefs)

        prop_covs_retained <- matrix(0, n_nodes, n_total_covariates)
        for(i in seq_len(n_nodes)){
          for(j in seq_len(n_total_covariates)){
            prop_covs_retained[i,j] <- 1 - countzero(booted_mrfs, i, j)
          }
        }
        rownames(prop_covs_retained) <- rownames(booted_mrfs[[1]]$direct_coefs)
        colnames(prop_covs_retained) <- colnames(booted_mrfs[[1]]$direct_coefs)

        #Create list of covariates that are not zero for each node in data
        key_covariates <- lapply(seq_len(n_nodes), function(x){
          cov_prop_retained <- apply(data.frame(prop_covs_retained)[x,],2,
                                     function(j) ifelse(j < 0.9, NA, j))
          cov_mean_coef <- as.vector(direct_coef_means[x,])
          cov_summary <- na.omit(cbind(cov_prop_retained, cov_mean_coef))
          cleaned_prop_retained <- cov_prop_retained[!is.na(cov_prop_retained)]
          cov_df <- data.frame(Proportion_retained = cleaned_prop_retained,
                               Mean_coefficient = cov_summary[,2])
          cov_df <- cov_df[order(-abs(cov_df[, 2])), ]
        })
        names(key_covariates) <- colnames(prepped_datas[[1]])[1:n_nodes]

        #Calculate mean indirect interaction coefficients from bootstrap samps
        indirect_coef_list <- booted_mrfs %>%
          purrr::map('indirect_coefs')

        indirect_coef_means <-lapply(seq_along(indirect_coef_list[[1]]), function(x){
          Reduce(`+`, sapply(indirect_coef_list, "[[", x)) / length(indirect_coef_list)
        })
        names(indirect_coef_means) <- names(indirect_coef_list[[1]])

        list(key_covariates = key_covariates,
             raw_coefs = direct_coef_list,
             indirect_coefs = indirect_coef_means)
      })
    }

  #### Calculate summary statistics of coefficients from bootstrapped models ####
  #Name each list element by its lambda1 value
  names(lambda_results) <- lambda1_seq

  #Calculate summary coefficient statistics across all lambda1 values
  all_direct_coef_list <- lambda_results %>%
    purrr::map('raw_coefs') %>%
    purrr::flatten()

  all_direct_coef_means <- apply(array(unlist(all_direct_coef_list),
                            c(nrow(lambda_results[[1]]$raw_coefs[[1]]),
                              ncol(lambda_results[[1]]$raw_coefs[[1]]),
                              n_bootstraps)), c(1, 2), mean)
  rownames(all_direct_coef_means) <- rownames(lambda_results[[1]]$raw_coefs[[1]])
  colnames(all_direct_coef_means) <- colnames(lambda_results[[1]]$raw_coefs[[1]])

  all_direct_coef_upper90 <- apply(array(unlist(all_direct_coef_list),
                                c(nrow(lambda_results[[1]]$raw_coefs[[1]]),
                                  ncol(lambda_results[[1]]$raw_coefs[[1]]),
                                  n_bootstraps)), c(1, 2),
                           function(x){quantile(x, probs = 0.95)})
  rownames(all_direct_coef_upper90) <- rownames(lambda_results[[1]]$raw_coefs[[1]])
  colnames(all_direct_coef_upper90) <- colnames(lambda_results[[1]]$raw_coefs[[1]])

  all_direct_coef_lower90 <- apply(array(unlist(all_direct_coef_list),
                                 c(nrow(lambda_results[[1]]$raw_coefs[[1]]),
                                   ncol(lambda_results[[1]]$raw_coefs[[1]]),
                                   n_bootstraps)), c(1, 2),
                           function(x){quantile(x, probs = 0.05)})
  rownames(all_direct_coef_lower90) <- rownames(lambda_results[[1]]$raw_coefs[[1]])
  colnames(all_direct_coef_lower90) <- colnames(lambda_results[[1]]$raw_coefs[[1]])

  #Calculate relative importance of key covariates across the set of lambda results
  coef_rel_importances <- t(apply(all_direct_coef_means[, -1], 1, function(i) i^2 / sum(i^2)))
  mean_key_coefs <- lapply(seq_len(n_nodes),function(x){
    if(length(which(coef_rel_importances[x, ] > 0.01)) == 1){
      node_coefs <- data.frame(Variable = names(which((coef_rel_importances[x, ] > 0.01) == T)),
                               Rel_importance = coef_rel_importances[x, which(coef_rel_importances[x, ] > 0.01)],
                               Mean_coef = all_direct_coef_means[x, 1 + which(coef_rel_importances[x, ] > 0.01)])
    } else {
      node_coefs <- data.frame(Variable = names(coef_rel_importances[x, which(coef_rel_importances[x, ] > 0.01)]),
                               Rel_importance = coef_rel_importances[x, which(coef_rel_importances[x, ] > 0.01)],
                               Mean_coef = all_direct_coef_means[x, 1 + which(coef_rel_importances[x, ] > 0.01)])
    }

    rownames(node_coefs) <- NULL

    node_coefs <- node_coefs[order(-node_coefs[, 2]), ]
  })
  names(mean_key_coefs) <- rownames(all_direct_coef_means)

  #Calculate higher order coefficient summary statistics
  all_indirect_coef_list <- lambda_results %>%
    purrr::map('indirect_coefs')

  all_indirect_coef_means <-lapply(seq_along(all_indirect_coef_list[[1]]), function(x){
    Reduce(`+`, sapply(all_indirect_coef_list, "[", x)) / length(all_indirect_coef_list)
  })
  names(all_indirect_coef_means) <- names(all_indirect_coef_list[[1]])

  return(list(lambda_results = lambda_results,
              direct_coef_means = all_direct_coef_means,
              direct_coef_upper90 = all_direct_coef_upper90,
              direct_coef_lower90 = all_direct_coef_lower90,
              indirect_coef_mean = all_indirect_coef_means,
              mean_key_coefs = mean_key_coefs))
}

