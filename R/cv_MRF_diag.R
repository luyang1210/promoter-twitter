#'MRF cross validation plots to optimise regularization parameters
#'
#'
#'This function runs cross validation of \code{\link{MRFcov}} models across a specified
#'range of l1−regularization values and produces simple diagnostic plots
#'to assess model predictive performance at each l1 value.
#'
#'
#'@param data Dataframe. The input data where the \code{n_nodes}
#'left-most variables are variables that are to be represented by nodes in the graph.
#'Note that \code{NA}'s are allowed for covariates. If present, these missing values
#'will be imputed from the distribution \code{rnorm(mean = 0, sd = 1)}, which assumes that
#'all covariates are scaled and centred (i.e. by using the function
#'\code{\link[base]{scale}} or similar)
#'@param min_lambda1 Positive numeric. The lowest l1−regularization value to be tested
#'@param max_lambda1 Positive numeric. The highest l1−regularization value to be tested
#'@param by_lambda1 Positive numeric. The increment of the l1 test_data sequence. The test sequence is generated by calling
#'\code{lamda1_seq = seq(min_lambda1, max_lambda1, by_lambda1)}
#'@param lambda2 Numeric (>= 0). Value for l2−regularization, where larger values lead
#'to stronger shrinking of coefficient magnitudes. Default is 0, but larger values
#'may be necessary for large or particularly sparse datasets
#'@param symmetrise The method to use for symmetrising corresponding parameter estimates
#'(which are taken from separate regressions). Options are \code{min} (take the coefficient with the
#'smallest absolute value), \code{max} (take the coefficient with the largest absolute value)
#'or \code{mean} (take the mean of the two coefficients). Default is \code{mean}
#'@param n_nodes Positive integer. The index of the last column in \code{data}
#'which is represented by a node in the final graph. Columns with index
#'greater than n_nodes are taken as covariates. Default is the number of
#'columns in \code{data}, corresponding to no additional covariates
#'@param n_cores Positive integer. The number of cores to spread the job across using
#'\code{\link[parallel]{makePSOCKcluster}}. Default is 1 (no parallelisation)
#'@param n_folds Integer. The number of folds for cross-validation. Default is 10
#'@param n_fold_runs Integer. The number of total training runs to perform at each
#'l1 regularization parameter. Defaults to \code{n_folds}
#'@param sample_seed Numeric. This seed will be used as the basis
#'for dividing data into folds. Default is a random seed
#'between 1 and 100000
#'@param n_covariates Positive integer. The number of covariates in \code{data}, before cross-multiplication
#'@param compare_null Logical. If \code{TRUE}, null models will also be run and plotted to
#'assess the influence of including covariates on model predictive performance.
#'Default is \code{FALSE}
#'@param family The response type. Responses can be quantitative continuous (\code{family = "gaussian"}),
#'non-negative counts (\code{family = "poisson"}) or binomial 1s and 0s (\code{family = "binomial"}).
#'@param plot Logical. If \code{TRUE}, \code{ggplot2} objects are returned. If \code{FALSE},
#'the prediction metrics are returned as a matrix. Default is \code{TRUE}
#'@param fixed_lambda Logical determining whether a model should be run by optimising l1 regularization
#'for each individual node. Default is \code{TRUE}
#'@return Either a \code{ggplot2} object plotting LOESS regressions of
#'relationships between l1−regularization values and predictive metrics, or
#'a matrix of prediction metrics (if \code{plot = FALSE})
#'
#'@seealso \code{\link{MRFcov}},\code{\link{predict_MRF}},
#'\code{\link{cv_MRF}},
#'\code{\link[penalized]{penalized}}
#'
#'@details \code{MRFcov} models are run across the specified sequence of \code{lambda1} values.
#'Cross validation is used to test model predictive capacity at each \code{lambda1}.
#'For each model, the observed presence-absence values of nodes in a test set of
#'\code{data} observations is predicted using outputs of an \code{MRFcov} model that is fit to
#'the remaining observations (training data) using \code{\link{cv_MRF}}.
#'Test and training \code{data} subsets are created using \code{\link[caret]{createFolds}}.
#'Plots showing
#'LOESS regressions of prediction metrics vs \code{lambda1} are returned
#'
#'@examples
#'\dontrun{
#'data("Bird.parasites")
#'cv_MRF_diag(data = Bird.parasites, min_lambda1 = 0.4,
#'            max_lambda1 = 2, by_lambda1 = 0.1,
#'            n_nodes = 4, n_cores = 3, family = 'binomial')}
#'@export
#'
cv_MRF_diag <- function(data, min_lambda1, max_lambda1, by_lambda1,
                        symmetrise, n_nodes, lambda2, n_cores,
                        sample_seed, n_folds, n_fold_runs, n_covariates,
                        compare_null, family, plot = TRUE, fixed_lambda = TRUE){

  #### Specify default parameter values and initiate warnings ####
  if(!(family %in% c('gaussian', 'poisson', 'binomial')))
    stop('Please select one of the three family options:
         "gaussian", "poisson", "binomial"')

  if(missing(symmetrise)){
    symmetrise <- 'mean'
  }

  if(missing(compare_null)) {
    compare_null <- FALSE
  }

  if(missing(n_folds)) {
    n_folds <- 10
  } else {
    if(sign(n_folds) == 1){
      #Make sure n_folds is a positive integer
      n_folds <- ceiling(n_folds)
    } else {
      stop('Please provide a positive integer for n_folds')
    }
  }

  if(missing(n_fold_runs)) {
    n_fold_runs <- n_folds
  } else {
    if(sign(n_fold_runs) == 1){
      #Make sure n_fold_runs is a positive integer
      n_fold_runs <- ceiling(n_fold_runs)
    } else {
      stop('Please provide a positive integer for n_fold_runs')
    }
  }

  if(missing(lambda2)) {
    lambda2 <- 0
  } else {
    if(lambda2 < 0){
      stop('Please provide a non-negative numeric value for lambda2')
    }
  }

  if(missing(n_cores)) {
    n_cores <- 1
  } else {
    if(sign(n_cores) != 1){
      stop('Please provide a positive integer for n_cores')
    } else{
      if(sfsmisc::is.whole(n_cores) == FALSE){
        stop('Please provide a positive integer for n_cores')
      }
    }
  }

  if(missing(n_nodes)) {
    warning('n_nodes not specified. using ncol(data) as default, assuming no covariates',
            call. = FALSE)
    n_nodes <- ncol(data)
    n_covariates <- 0
  } else {
    if(sign(n_nodes) != 1){
      stop('Please provide a positive integer for n_nodes')
    } else {
      if(sfsmisc::is.whole(n_nodes) == FALSE){
        stop('Please provide a positive integer for n_nodes')
      }
    }
  }

  if(missing(n_covariates)){
    n_covariates <- ncol(data) - n_nodes
  } else {
    if(sign(n_covariates) != 1){
      stop('Please provide a positive integer for n_covariates')
    } else {
      if(sfsmisc::is.whole(n_covariates) == FALSE){
        stop('Please provide a positive integer for n_covariates')
      }
    }
  }

  if(missing(sample_seed)) {
    sample_seed <- ceiling(runif(1, 0, 100000))
  }

  if(fixed_lambda){
  #### Run cross validation of MRF models
  if(family == 'binomial'){
    crossval_mrfs <- cv_MRF(data = data, min_lambda1 = min_lambda1,
                          max_lambda1 = max_lambda1,
                          by_lambda1 = by_lambda1, symmetrise = symmetrise,
                          lambda2 = lambda2,
                          n_nodes = n_nodes, n_cores = n_cores,
                          sample_seed = sample_seed,
                          n_folds = n_folds, n_fold_runs = n_fold_runs,
                          n_covariates = n_covariates)

  ### Extract predictive metrics for plotting
  plot_dat <- purrr::map_df(crossval_mrfs, magrittr::extract,
                  c('mean_pos_pred', 'lambda1', 'mean_tot_pred',
                    'mean_sensitivity',
                    'mean_specificity'))

  if(!compare_null){

    if(plot){
      output <- plot_binom_cv_diag(plot_dat, compare_null = FALSE)
    } else {
      output <- plot_dat
    }

  } else {
    #### If compare_null = TRUE, run models using no covariates for comparison
    crossval_mrf_nulls <- cv_MRF(data = data[ ,1:n_nodes], min_lambda1 = min_lambda1,
                            max_lambda1 = max_lambda1,
                            by_lambda1 = by_lambda1, symmetrise = symmetrise,
                            lambda2 = lambda2,
                            n_nodes = n_nodes, n_cores = n_cores,
                            sample_seed = sample_seed,
                            n_folds = n_folds, n_fold_runs = n_fold_runs)

    ### Extract null predictive metrics and combine with full metrics from above
    plot_dat_null <- purrr::map_df(crossval_mrf_nulls, magrittr::extract,
                              c('mean_pos_pred', 'mean_tot_pred',
                                'mean_sensitivity',
                                'mean_specificity'))

    colnames(plot_dat_null) <- c('mean_pos_pred_null','mean_tot_pred_null',
                                 'mean_sensitivity_null','mean_specificity_null')
    plot_dat <- cbind(plot_dat, plot_dat_null)

    if(plot){
    output <- plot_binom_cv_diag(plot_dat, compare_null = TRUE)
    } else {
      output <- plot_dat
    }
  }

  } else if(family == 'poisson') {
    crossval_mrfs <- cv_MRF_poisson(data = data, min_lambda1 = min_lambda1,
                            max_lambda1 = max_lambda1,
                            by_lambda1 = by_lambda1, symmetrise = symmetrise,
                            lambda2 = lambda2,
                            n_nodes = n_nodes, n_cores = n_cores,
                            sample_seed = sample_seed,
                            n_folds = n_folds, n_fold_runs = n_fold_runs,
                            n_covariates = n_covariates)

    ### Extract predictive metrics for plotting
    plot_dat <- purrr::map_df(crossval_mrfs, magrittr::extract,
                              c('Rsquared', 'lambda1', 'MSE'))

    if(!compare_null){
      if(plot){
      output <- plot_gauss_cv_diag(plot_dat, compare_null = FALSE)
      } else {
        output <- plot_dat
      }

    } else {
      #### If compare_null = TRUE, run models using no covariates for comparison
      crossval_mrf_nulls <- cv_MRF_poisson(data = data[ ,1:n_nodes], min_lambda1 = min_lambda1,
                                   max_lambda1 = max_lambda1,
                                   by_lambda1 = by_lambda1, symmetrise = symmetrise,
                                   lambda2 = lambda2,
                                   n_nodes = n_nodes, n_cores = n_cores,
                                   sample_seed = sample_seed,
                                   n_folds = n_folds, n_fold_runs = n_fold_runs)

      ### Extract null predictive metrics and combine with full metrics from above
      plot_dat_null <- purrr::map_df(crossval_mrf_nulls, magrittr::extract,
                                     c('Rsquared', 'MSE'))
      colnames(plot_dat_null) <- c('Rsquared.null', 'MSE.null')
      plot_dat <- cbind(plot_dat, plot_dat_null)

      if(plot){
      output <- plot_gauss_cv_diag(plot_dat, compare_null = TRUE)
      } else {
        output <- plot_dat
      }
    }
  } else if(family == 'gaussian') {
    crossval_mrfs <- cv_MRF_gaussian(data = data, min_lambda1 = min_lambda1,
                                    max_lambda1 = max_lambda1,
                                    by_lambda1 = by_lambda1, symmetrise = symmetrise,
                                    lambda2 = lambda2,
                                    n_nodes = n_nodes, n_cores = n_cores,
                                    sample_seed = sample_seed,
                                    n_folds = n_folds, n_fold_runs = n_fold_runs,
                                    n_covariates = n_covariates)

    ### Extract predictive metrics for plotting
    plot_dat <- purrr::map_df(crossval_mrfs, magrittr::extract,
                              c('Rsquared', 'lambda1', 'MSE'))

    if(!compare_null){
      if(plot){
        output <- plot_gauss_cv_diag(plot_dat, compare_null = FALSE)
      } else {
        output <- plot_dat
      }

    } else {
      #### If compare_null = TRUE, run models using no covariates for comparison
      crossval_mrf_nulls <- cv_MRF_gaussian(data = data[ ,1:n_nodes], min_lambda1 = min_lambda1,
                                           max_lambda1 = max_lambda1,
                                           by_lambda1 = by_lambda1, symmetrise = symmetrise,
                                           lambda2 = lambda2,
                                           n_nodes = n_nodes, n_cores = n_cores,
                                           sample_seed = sample_seed,
                                           n_folds = n_folds, n_fold_runs = n_fold_runs)

      ### Extract null predictive metrics and combine with full metrics from above
      plot_dat_null <- purrr::map_df(crossval_mrf_nulls, magrittr::extract,
                                     c('Rsquared', 'MSE'))
      colnames(plot_dat_null) <- c('Rsquared.null', 'MSE.null')
      plot_dat <- cbind(plot_dat, plot_dat_null)

      if(plot){
        output <- plot_gauss_cv_diag(plot_dat, compare_null = TRUE)
      } else {
        output <- plot_dat
      }
    }
  }

  } else {

    #### If using node-specific optimisation, only a single model is needed ####
    if(missing(lambda2)){
      lambda2 <- 0
    }

    # Lambda parameters not needed if fixed_lambda = FALSE
    if(missing(min_lambda1)){
      min_lambda1 <- 0
    }

    if(missing(max_lambda1)){
      max_lambda1 <- 0
    }

    if(missing(by_lambda1)){
      by_lambda1 <- 0
    }

    if(family == 'binomial'){
      mrf <- MRFcov(data = data,
                    lambda2 = lambda2,
                    symmetrise =  symmetrise,
                    n_nodes = n_nodes,
                    n_cores = n_cores,
                    cv = TRUE, family = 'binomial')

      if(compare_null){
        mrf_null <- MRFcov(data = data[ ,1:n_nodes],
                           lambda2 = lambda2,
                           symmetrise =  symmetrise,
                           n_nodes = n_nodes,
                           n_cores = n_cores,
                           cv = TRUE, family = 'binomial')
      }
    }

  if(family == 'poisson'){
    mrf <- MRFcov(data = data,
                  lambda2 = lambda2,
                  symmetrise =  symmetrise,
                  n_nodes = n_nodes,
                  n_cores = n_cores,
                  cv = TRUE, family = 'poisson')

    if(compare_null){
      mrf_null <- MRFcov(data = data[ ,1:n_nodes],
                    lambda2 = lambda2,
                    symmetrise =  symmetrise,
                    n_nodes = n_nodes,
                    n_cores = n_cores,
                    cv = TRUE, family = 'poisson')
    }
  }

  if(family == 'gaussian'){
    mrf <- MRFcov(data = data,
                   lambda2 = lambda2,
                   symmetrise =  symmetrise,
                   n_nodes = n_nodes,
                   n_cores = n_cores,
                   cv = TRUE, family = 'gaussian')

    if(compare_null){
      mrf_null <- MRFcov(data = data[ ,1:n_nodes],
                         lambda2 = lambda2,
                         symmetrise =  symmetrise,
                         n_nodes = n_nodes,
                         n_cores = n_cores,
                         cv = TRUE, family = 'gaussian')
    }
  }

  if(family == 'binomial'){
    folds <- caret::createFolds(rownames(data), 10)
    cv_predictions <- lapply(seq_len(10), function(k){
      test_data <- data[folds[[k]], ]
      predictions <- predict_MRF(test_data, mrf)

      #Calculate positive and negative predictive values
      true_pos <- false_pos <- true_neg <- false_neg <- matrix(NA, ncol = ncol(predictions[[2]]),
                                                               nrow = nrow(predictions[[2]]))
      for(i in seq_len(nrow(true_pos))){
        for(j in seq_len(ncol(true_pos))){
          true_pos[i, j] <- isTRUE(all.equal(as.numeric(predictions[[2]][i, j]),
                                             as.numeric(test_data[i, j]))) &
            isTRUE(all.equal(as.numeric(predictions[[2]][i, j]), 1))

          false_pos[i, j] <- !isTRUE(all.equal(as.numeric(predictions[[2]][i, j]),
                                               as.numeric(test_data[i, j]))) &
            isTRUE(all.equal(as.numeric(predictions[[2]][i, j]), 1))

          true_neg[i, j] <- isTRUE(all.equal(as.numeric(predictions[[2]][i, j]),
                                             as.numeric(test_data[i, j]))) &
            isTRUE(all.equal(as.numeric(predictions[[2]][i, j]), 0))

          false_neg[i, j] <- !isTRUE(all.equal(as.numeric(predictions[[2]][i, j]),
                                               as.numeric(test_data[i, j]))) &
            isTRUE(all.equal(as.numeric(predictions[[2]][i, j]), 0))
        }
      }

      #Calculate diagnostic predictive values
      pos_pred <- sum(true_pos, na.rm = TRUE) /
        (sum(true_pos, na.rm = TRUE) + sum(false_pos, na.rm = TRUE))
      neg_pred <- sum(true_neg, na.rm = TRUE) /
        (sum(true_neg, na.rm = TRUE) + sum(false_neg, na.rm = TRUE))
      sensitivity <- sum(true_pos, na.rm = TRUE) /
        (sum(true_pos, na.rm = TRUE) + sum(false_neg, na.rm = TRUE))
      specificity <- sum(true_neg, na.rm = TRUE) /
        (sum(true_neg, na.rm = TRUE) + sum(false_pos, na.rm = TRUE))
      tot_pred <- (sum(true_pos, na.rm = TRUE) + sum(true_neg, na.rm = TRUE)) /
        (length(true_pos))

    list(mean_pos_pred = mean(pos_pred, na.rm = TRUE),
         mean_neg_pred = mean(neg_pred, na.rm = TRUE),
         mean_tot_pred = mean(tot_pred, na.rm = TRUE),
         mean_sensitivity = mean(sensitivity, na.rm = TRUE),
         mean_specificity = mean(specificity, na.rm = TRUE))
    })

    plot_dat <- purrr::map_df(cv_predictions, magrittr::extract,
                              c('mean_pos_pred', 'mean_tot_pred',
                                'mean_sensitivity',
                                'mean_specificity'))

    if(compare_null){
      cv_predictions_null <- lapply(seq_len(10), function(k){
        test_data <- data[folds[[k]], 1:n_nodes]
        predictions <- predict_MRF(test_data, mrf_null)

        #Calculate positive and negative predictive values
        true_pos <- false_pos <- true_neg <- false_neg <- matrix(NA, ncol = ncol(predictions[[2]]),
                                                                 nrow = nrow(predictions[[2]]))
        for(i in seq_len(nrow(true_pos))){
          for(j in seq_len(ncol(true_pos))){
            true_pos[i, j] <- isTRUE(all.equal(as.numeric(predictions[[2]][i, j]),
                                               as.numeric(test_data[i, j]))) &
              isTRUE(all.equal(as.numeric(predictions[[2]][i, j]), 1))

            false_pos[i, j] <- !isTRUE(all.equal(as.numeric(predictions[[2]][i, j]),
                                                 as.numeric(test_data[i, j]))) &
              isTRUE(all.equal(as.numeric(predictions[[2]][i, j]), 1))

            true_neg[i, j] <- isTRUE(all.equal(as.numeric(predictions[[2]][i, j]),
                                               as.numeric(test_data[i, j]))) &
              isTRUE(all.equal(as.numeric(predictions[[2]][i, j]), 0))

            false_neg[i, j] <- !isTRUE(all.equal(as.numeric(predictions[[2]][i, j]),
                                                 as.numeric(test_data[i, j]))) &
              isTRUE(all.equal(as.numeric(predictions[[2]][i, j]), 0))
          }
        }

        #Calculate diagnostic predictive values
        pos_pred <- sum(true_pos, na.rm = TRUE) /
          (sum(true_pos, na.rm = TRUE) + sum(false_pos, na.rm = TRUE))
        neg_pred <- sum(true_neg, na.rm = TRUE) /
          (sum(true_neg, na.rm = TRUE) + sum(false_neg, na.rm = TRUE))
        sensitivity <- sum(true_pos, na.rm = TRUE) /
          (sum(true_pos, na.rm = TRUE) + sum(false_neg, na.rm = TRUE))
        specificity <- sum(true_neg, na.rm = TRUE) /
          (sum(true_neg, na.rm = TRUE) + sum(false_pos, na.rm = TRUE))
        tot_pred <- (sum(true_pos, na.rm = TRUE) + sum(true_neg, na.rm = TRUE)) /
          (length(true_pos))

        list(mean_pos_pred = mean(pos_pred, na.rm = TRUE),
             mean_neg_pred = mean(neg_pred, na.rm = TRUE),
             mean_tot_pred = mean(tot_pred, na.rm = TRUE),
             mean_sensitivity = mean(sensitivity, na.rm = TRUE),
             mean_specificity = mean(specificity, na.rm = TRUE))
      })

      plot_dat_null <- purrr::map_df(cv_predictions_null, magrittr::extract,
                                c('mean_pos_pred','mean_tot_pred',
                                  'mean_sensitivity',
                                  'mean_specificity'))
      plot_dat$model <- 'CRF'
      plot_dat_null$model <- 'MRF (no covariates)'
      plot_dat <- rbind(plot_dat, plot_dat_null)

      if(plot){
        output <- plot_binom_cv_diag_optim(plot_dat, compare_null = TRUE)
      } else {
        output <- plot_dat
      }

    } else {
      if(plot){
        output <- plot_binom_cv_diag_optim(plot_dat, compare_null = FALSE)
      } else {
        output <- plot_dat
      }
    }
  }

  if(family == 'gaussian' || family == 'poisson'){
    folds <- caret::createFolds(rownames(data), 10)
    cv_predictions <- lapply(seq_len(10), function(k){
      test_data <- data[folds[[k]], ]
      predictions <- predict_MRF(test_data, mrf)
      Rsquared <- vector()
      MSE <- vector()
      for(i in seq_len(ncol(predictions))){
        Rsquared[i] <- cor.test(test_data[, i], predictions[, i])[[4]]
        MSE[i] <- mean(residuals(lm(test_data[, i] ~ predictions[, i])) ^ 2)
      }
      list(Rsquared = mean(Rsquared, na.rm = T), MSE = mean(MSE, na.rm = T))
    })
    plot_dat <- purrr::map_df(cv_predictions, magrittr::extract,
                              c('Rsquared', 'MSE'))

    if(compare_null){
      cv_predictions_null <- lapply(seq_len(10), function(k){
        test_data <- data[folds[[k]], 1:n_nodes]
        predictions <- predict_MRF(test_data, mrf_null)
        Rsquared <- vector()
        MSE <- vector()
        for(i in seq_len(ncol(predictions))){
          Rsquared[i] <- cor.test(test_data[, i], predictions[, i])[[4]]
          MSE[i] <- mean(residuals(lm(test_data[, i] ~ predictions[, i])) ^ 2)
        }
        list(Rsquared = mean(Rsquared, na.rm = T), MSE = mean(MSE, na.rm = T))
      })
      plot_dat_null <- purrr::map_df(cv_predictions_null, magrittr::extract,
                                c('Rsquared', 'MSE'))
      plot_dat$model <- 'CRF'
      plot_dat_null$model <- 'MRF (no covariates)'
      plot_dat <- rbind(plot_dat, plot_dat_null)

      if(plot){
        output <- plot_gauss_cv_diag_optim(plot_dat, compare_null = TRUE)
      } else {
        output <- plot_dat
      }

    } else {
      if(plot){
        output <- plot_gauss_cv_diag_optim(plot_dat, compare_null = FALSE)
      } else {
        output <- plot_dat
      }
    }
  }
}

  return(output)
}
