#'MRF cross validation plots to optimise regularization parameters
#'
#'
#'This function runs cross validation of \code{\link{MRFcov}} models across a specified
#'range of l1−regularization values and produces simple diagnostic plots
#'to assess model predictive performance at each l1 value.
#'
#'
#'@param data Dataframe. The input data where the \code{n_nodes}
#'left-most variables are binary occurrences to be represented by nodes in the graph.
#'Note that \code{NA}'s are allowed for covariates. If present, these missing values
#'will be imputed from the distribution \code{rnorm(mean = 0, sd = 1)}, which assumes that
#'all covariates are scaled and centred (i.e. by using the function
#'\code{\link[base]{scale}} or similar)
#'@param min_lambda1 Positive numeric. The lowest l1−regularization value to be tested
#'@param max_lambda1 Positive numeric. The highest l1−regularization value to be tested
#'@param by_lambda1 Positive numeric. The increment of the l1 test_data sequence. The test sequence is generated by calling
#'\code{lamda1_seq = seq(min_lambda1, max_lambda1, by_lambda1)}
#'@param lambda2 Numeric (>= 0). Value for l2−regularization, where larger values lead
#'to stronger shrinking of coefficient magnitudes. Default is 0, but larger values
#'may be necessary for large or particularly sparse datasets
#'@param separate_min Logical. If \strong{TRUE}, interaction coefficients will use the minimum absolute value of
#'the corresponding parameter estimates, which are taken from separate logistic regressions,
#' in the symmetric postprocessed coefficient matrix. Else use the maximum. Default is \strong{FALSE}
#'@param n_nodes Positive integer. The index of the last column in \code{data}
#'which is represented by a node in the final graph. Columns with index
#'greater than n_nodes are taken as covariates. Default is the number of
#'columns in \code{data}, corresponding to no additional covariates
#'@param n_cores Positive integer. The number of cores to spread the job across using
#'\code{\link[parallel]{makePSOCKcluster}}. Default is 1 (no parallelisation)
#'@param n_folds Integer. The number of folds for cross-validation. Default is 10
#'@param n_fold_runs Integer. The number of total training runs to perform at each
#'l1 regularization parameter. Defaults to \code{n_folds}
#'@param sample_seed Numeric. This seed will be used as the basis
#'for dividing data into folds. Default is a random seed
#'between 1 and 100000
#'@param n_covariates Positive integer. The number of covariates in \code{data}, before cross-multiplication
#'@param compare_null Logical. If \code{TRUE}, null models will also be run and plotted to
#'assess the influence of including covariates on model predictive performance.
#'Default is \code{FALSE}
#'@return A \code{ggplot2} object plotting LOESS regressions of
#'relationships between l1−regularization values and predictive metrics
#'
#'@seealso \code{\link{MRFcov}},\code{\link{predict_MRF}},
#'\code{\link{cv_MRF}},
#'\code{\link[penalized]{penalized}}
#'
#'@export
#'
cv_MRF_diag <- function(data, min_lambda1, max_lambda1, by_lambda1,
                        separate_min, n_nodes, lambda2, n_cores,
                        sample_seed, n_folds, n_fold_runs, n_covariates,
                        compare_null){

  #### Specify default parameter values and initiate warnings ####
  if(missing(separate_min)) {
    separate_min <- FALSE
  }

  if(missing(compare_null)) {
    compare_null <- FALSE
  }

  if(missing(n_folds)) {
    n_folds <- 10
  } else {
    if(sign(n_folds) == 1){
      #Make sure n_folds is a positive integer
      n_folds <- ceiling(n_folds)
    } else {
      stop('Please provide a positive integer for n_folds')
    }
  }

  if(missing(n_fold_runs)) {
    n_fold_runs <- n_folds
  } else {
    if(sign(n_fold_runs) == 1){
      #Make sure n_fold_runs is a positive integer
      n_fold_runs <- ceiling(n_fold_runs)
    } else {
      stop('Please provide a positive integer for n_fold_runs')
    }
  }

  if(missing(lambda2)) {
    lambda2 <- 0
  } else {
    if(lambda2 < 0){
      stop('Please provide a non-negative numeric value for lambda2')
    }
  }

  if(missing(n_cores)) {
    n_cores <- 1
  } else {
    if(sign(n_cores) != 1){
      stop('Please provide a positive integer for n_cores')
    } else{
      if(sfsmisc::is.whole(n_cores) == FALSE){
        stop('Please provide a positive integer for n_cores')
      }
    }
  }

  if(missing(n_nodes)) {
    warning('n_nodes not specified. using ncol(data) as default, assuming no covariates',
            call. = FALSE)
    n_nodes <- ncol(data)
    n_covariates <- 0
  } else {
    if(sign(n_nodes) != 1){
      stop('Please provide a positive integer for n_nodes')
    } else {
      if(sfsmisc::is.whole(n_nodes) == FALSE){
        stop('Please provide a positive integer for n_nodes')
      }
    }
  }

  if(missing(n_covariates)){
    n_covariates <- ncol(data) - n_nodes
  } else {
    if(sign(n_covariates) != 1){
      stop('Please provide a positive integer for n_covariates')
    } else {
      if(sfsmisc::is.whole(n_covariates) == FALSE){
        stop('Please provide a positive integer for n_covariates')
      }
    }
  }

  if(missing(sample_seed)) {
    sample_seed <- ceiling(runif(1, 0, 100000))
  }

  #### Run cross validation of MRF models
  crossval_mrfs <- cv_MRF(data = data, min_lambda1 = min_lambda1,
                          max_lambda1 = max_lambda1,
                          by_lambda1 = by_lambda1, separate_min = separate_min,
                          lambda2 = lambda2,
                          n_nodes = n_nodes, n_cores = n_cores,
                          sample_seed = sample_seed,
                          n_folds = n_folds, n_fold_runs = n_fold_runs,
                          n_covariates = n_covariates)

  ### Extract predictive metrics for plotting
  plot_dat <- purrr::map_df(crossval_mrfs, magrittr::extract,
                  c('mean_pos_pred', 'lambda1', 'mean_tot_pred',
                    'mean_sensitivity',
                    'mean_specificity'))

  if(!compare_null){
  #### Plot predictive metrics with LOESS smoohts and return as a grid ####
  scaleFUN <- function(x) sprintf("%.3f", x)

  plot1 <- ggplot2::ggplot(plot_dat, ggplot2::aes(x = lambda1, y = mean_tot_pred)) +
    ggplot2::geom_smooth(method = 'loess', col = 'red4', fill = 'red4',
                size = 0.5, level = 0.99, alpha = 0.3) +
    ggplot2::theme_bw() +
    ggplot2::theme(axis.text.x = ggplot2::element_text(size = 8),
          axis.text.y = ggplot2::element_text(size = 8)) +
    ggplot2::theme(panel.grid.major = ggplot2::element_blank(),
          panel.grid.minor = ggplot2::element_blank()) +
    ggplot2::scale_y_continuous(labels=scaleFUN) +
    ggplot2::labs(y = 'True predictions',
         x = '') +
    ggplot2::theme(legend.position = "none")

  plot2 <- ggplot2::ggplot(plot_dat, ggplot2::aes(x = lambda1, y = mean_pos_pred)) +
    ggplot2::geom_smooth(method = 'loess',col = 'red4', fill = 'red4',
                size = 0.5, level = 0.99, alpha = 0.3) +
    ggplot2::theme_bw() +
    ggplot2::theme(axis.text.x = ggplot2::element_text(size = 8),
          axis.text.y = ggplot2::element_text(size = 8)) +
    ggplot2::theme(panel.grid.major = ggplot2::element_blank(),
          panel.grid.minor = ggplot2::element_blank()) +
    ggplot2::scale_y_continuous(labels = scaleFUN) +
    ggplot2::labs(y = 'PPV',
         x = '')

  plot3 <- ggplot2::ggplot(plot_dat, ggplot2::aes(x = lambda1, y = mean_specificity)) +
    ggplot2::geom_smooth(method = 'loess', col = 'red4', fill = 'red4',
                size=0.5, level = 0.99, alpha = 0.3) +
    ggplot2::theme_bw() +
    ggplot2::theme(axis.text.x = ggplot2::element_text(size = 8),
          axis.text.y = ggplot2::element_text(size = 8)) +
    ggplot2::theme(panel.grid.major = ggplot2::element_blank(),
          panel.grid.minor = ggplot2::element_blank()) +
    ggplot2::scale_y_continuous(labels = scaleFUN) +
    ggplot2::labs(y = 'Specificity',
         x = '')

  plot4 <- ggplot2::ggplot(plot_dat, ggplot2::aes(x = lambda1,
                                                  y = mean_sensitivity)) +
    ggplot2::geom_smooth(method = 'loess',col = 'red4',fill = 'red4',
                size=0.5, level = 0.99, alpha = 0.3) +
    ggplot2::theme_bw() +
    ggplot2::theme(axis.text.x = ggplot2::element_text(size = 8),
          axis.text.y = ggplot2::element_text(size = 8)) +
    ggplot2::theme(panel.grid.major = ggplot2::element_blank(),
          panel.grid.minor = ggplot2::element_blank()) +
    ggplot2::scale_y_continuous(labels = scaleFUN) +
    ggplot2::labs(y = 'Sensitivity',
         x = expression(paste("Regularization parameter ", lambda)))

  output <- gridExtra::grid.arrange(plot1, plot2, plot3, plot4, ncol = 1,
                      heights = c(1, 1, 1, 1))
  } else {
    #### If compare_null = TRUE, run models using no covariates for comparison
    crossval_mrf_nulls <- cv_MRF(data = data[ ,1:n_nodes], min_lambda1 = min_lambda1,
                            max_lambda1 = max_lambda1,
                            by_lambda1 = by_lambda1, separate_min = separate_min,
                            lambda2 = lambda2,
                            n_nodes = n_nodes, n_cores = n_cores,
                            sample_seed = sample_seed,
                            n_folds = n_folds, n_fold_runs = n_fold_runs)

    ### Extract null predictive metrics and combine with full metrics from above
    plot_dat_null <- purrr::map_df(crossval_mrf_nulls, magrittr::extract,
                              c('mean_pos_pred', 'mean_tot_pred',
                                'mean_sensitivity',
                                'mean_specificity'))

    colnames(plot_dat_null) <- c('mean_pos_pred_null','mean_tot_pred_null',
                                 'mean_sensitivity_null','mean_specificity_null')
    plot_dat <- cbind(plot_dat, plot_dat_null)

    #### Plot predictive metrics with LOESS smoohts and return as a grid ####
    scaleFUN <- function(x) sprintf("%.3f", x)

    plot1 <- ggplot2::ggplot(plot_dat, ggplot2::aes(x = lambda1)) +
      ggplot2::geom_smooth(ggplot2::aes(y = mean_tot_pred, col = 'MRFcov'),
                           method = 'loess', col = 'red4', fill = 'red4',
                           size = 0.5, level = 0.99, alpha = 0.3) +
      ggplot2::geom_smooth(ggplot2::aes(y = mean_tot_pred_null, col = 'MRF'), method = 'loess',
                           col = 'blue', fill = 'blue',
                           size = 0.5, level = 0.99, alpha = 0.3) +
      ggplot2::theme_bw() +
      ggplot2::theme(axis.text.x = ggplot2::element_text(size = 8),
                     axis.text.y = ggplot2::element_text(size = 8)) +
      ggplot2::theme(panel.grid.major = ggplot2::element_blank(),
                     panel.grid.minor = ggplot2::element_blank()) +
      ggplot2::scale_y_continuous(labels=scaleFUN) +
      ggplot2::labs(y = 'True predictions',
                    x = '') +
      ggplot2::scale_colour_manual(name = "", values = c("blue", "red4")) +
      ggplot2::guides(colour = ggplot2::guide_legend(override.aes = list(fill = 'white')))
      ggplot2::theme(legend.position = "top")

    plot2 <- ggplot2::ggplot(plot_dat, ggplot2::aes(x = lambda1, y = mean_pos_pred)) +
      ggplot2::geom_smooth(method = 'loess',col = 'red4', fill = 'red4',
                           size = 0.5, level = 0.99, alpha = 0.3) +
      ggplot2::geom_smooth(ggplot2::aes(y = mean_pos_pred_null), method = 'loess',
                           col = 'blue', fill = 'blue',
                           size = 0.5, level = 0.99, alpha = 0.3) +
      ggplot2::theme_bw() +
      ggplot2::theme(axis.text.x = ggplot2::element_text(size = 8),
                     axis.text.y = ggplot2::element_text(size = 8)) +
      ggplot2::theme(panel.grid.major = ggplot2::element_blank(),
                     panel.grid.minor = ggplot2::element_blank()) +
      ggplot2::scale_y_continuous(labels = scaleFUN) +
      ggplot2::labs(y = 'PPV',
                    x = '')

    plot3 <- ggplot2::ggplot(plot_dat, ggplot2::aes(x = lambda1, y = mean_specificity)) +
      ggplot2::geom_smooth(method = 'loess', col = 'red4', fill = 'red4',
                           size=0.5, level = 0.99, alpha = 0.3) +
      ggplot2::geom_smooth(ggplot2::aes(y = mean_specificity_null), method = 'loess',
                           col = 'blue', fill = 'blue',
                           size = 0.5, level = 0.99, alpha = 0.3) +
      ggplot2::theme_bw() +
      ggplot2::theme(axis.text.x = ggplot2::element_text(size = 8),
                     axis.text.y = ggplot2::element_text(size = 8)) +
      ggplot2::theme(panel.grid.major = ggplot2::element_blank(),
                     panel.grid.minor = ggplot2::element_blank()) +
      ggplot2::scale_y_continuous(labels = scaleFUN) +
      ggplot2::labs(y = 'Specificity',
                    x = '')

    plot4 <- ggplot2::ggplot(plot_dat, ggplot2::aes(x = lambda1,
                                                    y = mean_sensitivity)) +
      ggplot2::geom_smooth(method = 'loess',col = 'red4',fill = 'red4',
                           size=0.5, level = 0.99, alpha = 0.3) +
      ggplot2::geom_smooth(ggplot2::aes(y = mean_sensitivity_null), method = 'loess',
                           col = 'blue', fill = 'blue',
                           size = 0.5, level = 0.99, alpha = 0.3) +
      ggplot2::theme_bw() +
      ggplot2::theme(axis.text.x = ggplot2::element_text(size = 8),
                     axis.text.y = ggplot2::element_text(size = 8)) +
      ggplot2::theme(panel.grid.major = ggplot2::element_blank(),
                     panel.grid.minor = ggplot2::element_blank()) +
      ggplot2::scale_y_continuous(labels = scaleFUN) +
      ggplot2::labs(y = 'Sensitivity',
                    x = expression(paste("Regularization parameter ", lambda)))

    output <- gridExtra::grid.arrange(plot1, plot2, plot3, plot4, ncol = 1,
                                   heights = c(1.4, 1, 1, 1))
  }

  return(output)
}
